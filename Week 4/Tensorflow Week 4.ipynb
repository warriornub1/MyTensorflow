{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPj42x4Ax7/hnrlI/t1y784"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QQ-aW12flZBU","executionInfo":{"status":"ok","timestamp":1691585489531,"user_tz":-480,"elapsed":1180,"user":{"displayName":"Kah Yong Chua","userId":"02499348339145863754"}},"outputId":"94a24d4e-ef29-4a1f-8c77-d0842c786e9a"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-08-09 12:51:27--  https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 209.85.147.128, 142.250.125.128, 142.250.136.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|209.85.147.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 149574867 (143M) [application/zip]\n","Saving to: ‘horse-or-human.zip’\n","\n","horse-or-human.zip  100%[===================>] 142.65M   188MB/s    in 0.8s    \n","\n","2023-08-09 12:51:28 (188 MB/s) - ‘horse-or-human.zip’ saved [149574867/149574867]\n","\n","--2023-08-09 12:51:28--  https://storage.googleapis.com/tensorflow-1-public/course2/week3/validation-horse-or-human.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 209.85.147.128, 142.250.125.128, 142.250.136.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|209.85.147.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 11480187 (11M) [application/zip]\n","Saving to: ‘validation-horse-or-human.zip’\n","\n","validation-horse-or 100%[===================>]  10.95M  --.-KB/s    in 0.1s    \n","\n","2023-08-09 12:51:29 (88.9 MB/s) - ‘validation-horse-or-human.zip’ saved [11480187/11480187]\n","\n"]}],"source":["# Import the training set\n","!wget https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip\n","\n","# Import the validation set\n","!wget https://storage.googleapis.com/tensorflow-1-public/course2/week3/validation-horse-or-human.zip"]},{"cell_type":"code","source":["import zipfile\n","\n","# Unzip training set\n","local_zip = './horse-or-human.zip'\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('./horse-or-human')\n","\n","# Unzip validation set\n","local_zip = './validation-horse-or-human.zip'\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('./validation-horse-or-human')\n","\n","zip_ref.close()"],"metadata":{"id":"2s0eF99tmwC8","executionInfo":{"status":"ok","timestamp":1691585490309,"user_tz":-480,"elapsed":782,"user":{"displayName":"Kah Yong Chua","userId":"02499348339145863754"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","# Directory with our training horse pictures\n","train_horse_dir = os.path.join('./horse-or-human/horses')\n","\n","# Directory with our training human pictures\n","train_human_dir = os.path.join('./horse-or-human/humans')\n","\n","# Directory with valdiation horse pictures\n","validation_horse_dir= os.path.join('./validation-horse-or-human/horses')\n","\n","# Directory with valdiation human pictures\n","validation_human_dir = os.path.join('./validation-horse-or-human/humans')\n","\n","\n","train_horse_names = os.listdir(train_horse_dir)\n","print(train_horse_names[:10])\n","\n","train_human_names = os.listdir(train_human_dir)\n","print(train_human_names[:10])\n","\n","validation_horse_names = os.listdir(validation_horse_dir)\n","print(f'VAL SET HORSES: {validation_horse_names[:10]}')\n","\n","validation_human_names = os.listdir(validation_human_dir)\n","print(f'VAL SET HUMANS: {validation_human_names[:10]}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0A9209Gngjo","executionInfo":{"status":"ok","timestamp":1691585596691,"user_tz":-480,"elapsed":10,"user":{"displayName":"Kah Yong Chua","userId":"02499348339145863754"}},"outputId":"e44ec60c-bb7a-428a-96e0-fee6c869bdb5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["['horse09-8.png', 'horse30-0.png', 'horse12-0.png', 'horse26-1.png', 'horse45-2.png', 'horse30-9.png', 'horse43-2.png', 'horse04-5.png', 'horse29-7.png', 'horse21-8.png']\n","['human06-29.png', 'human08-30.png', 'human13-22.png', 'human10-16.png', 'human16-12.png', 'human09-03.png', 'human14-25.png', 'human14-11.png', 'human11-23.png', 'human01-15.png']\n","VAL SET HORSES: ['horse6-161.png', 'horse3-011.png', 'horse5-083.png', 'horse4-588.png', 'horse5-164.png', 'horse5-100.png', 'horse6-153.png', 'horse3-055.png', 'horse5-303.png', 'horse4-389.png']\n","VAL SET HUMANS: ['valhuman04-08.png', 'valhuman03-14.png', 'valhuman05-07.png', 'valhuman01-21.png', 'valhuman01-01.png', 'valhuman02-24.png', 'valhuman05-25.png', 'valhuman03-20.png', 'valhuman05-00.png', 'valhuman03-08.png']\n"]}]},{"cell_type":"code","source":["print(f'total training horse images: {len(os.listdir(train_horse_dir))}')\n","print(f'total training human images: {len(os.listdir(train_human_dir))}')\n","print(f'total validation horse images: {len(os.listdir(validation_horse_dir))}')\n","print(f'total validation human images: {len(os.listdir(validation_human_dir))}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-VbB1KtioFog","executionInfo":{"status":"ok","timestamp":1691585605146,"user_tz":-480,"elapsed":7,"user":{"displayName":"Kah Yong Chua","userId":"02499348339145863754"}},"outputId":"eb38730e-1cc6-417e-aa8d-b4931ab30ba7"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["total training horse images: 500\n","total training human images: 527\n","total validation horse images: 128\n","total validation human images: 128\n"]}]},{"cell_type":"code","source":["%matplotlib inline\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","# Parameters for our graph; we'll output images in a 4x4 configuration\n","nrows = 4\n","ncols = 4\n","\n","# Index for iterating over images\n","pic_index = 0\n","\n","# Set up matplotlib fig, and size it to fit 4x4 pics\n","fig = plt.gcf()\n","fig.set_size_inches(ncols * 4, nrows * 4)\n","\n","pic_index += 8\n","next_horse_pix = [os.path.join(train_horse_dir, fname)\n","                for fname in train_horse_names[pic_index-8:pic_index]]\n","next_human_pix = [os.path.join(train_human_dir, fname)\n","                for fname in train_human_names[pic_index-8:pic_index]]\n","\n","for i, img_path in enumerate(next_horse_pix+next_human_pix):\n","  # Set up subplot; subplot indices start at 1\n","  sp = plt.subplot(nrows, ncols, i + 1)\n","  sp.axis('Off') # Don't show axes (or gridlines)\n","\n","  img = mpimg.imread(img_path)\n","  plt.imshow(img)\n","\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":660,"output_embedded_package_id":"1Kj0wrx1R2nQMskHBCdL3Q8whnEVEDKSE"},"id":"NjyQZfvRoWiW","executionInfo":{"status":"ok","timestamp":1691573402173,"user_tz":-480,"elapsed":5759,"user":{"displayName":"Kah Yong Chua","userId":"02499348339145863754"}},"outputId":"0e3aba77-da5f-4aa0-d470-d61eb79be29e"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["# Building a Small Model from Scratch"],"metadata":{"id":"PtEQYanyofFz"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","model = tf.keras.models.Sequential([\n","    # First convolution layer\n","    tf.keras.layers.Conv2D(16, (3, 3), activation = 'relu', input_shape = (300, 300, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","\n","    # Second convolution layer\n","    tf.keras.layers.Conv2D(32, (3,3), activation = 'relu'),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","\n","    # Third convolution layer\n","    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","\n","    # The fourth convolution\n","    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","\n","    # The fifth convolution\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","\n","    # Flatten the results to feed into a DNN\n","    tf.keras.layers.Flatten(),\n","\n","    # 512 nueron hidden layer\n","    tf.keras.layers.Dense(512, activation = 'relu'),\n","\n","    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n","    tf.keras.layers.Dense(1, activation = 'sigmoid')\n","])"],"metadata":{"id":"JfFyll6ToaAt","executionInfo":{"status":"ok","timestamp":1691585636935,"user_tz":-480,"elapsed":7201,"user":{"displayName":"Kah Yong Chua","userId":"02499348339145863754"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PYNf3d5nqFHB","executionInfo":{"status":"ok","timestamp":1691585652240,"user_tz":-480,"elapsed":342,"user":{"displayName":"Kah Yong Chua","userId":"02499348339145863754"}},"outputId":"035290af-0cb3-4ebd-a71f-70ef281c41b3"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 298, 298, 16)      448       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 149, 149, 16)     0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 147, 147, 32)      4640      \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 73, 73, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 71, 71, 64)        18496     \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 35, 35, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 33, 33, 64)        36928     \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 16, 16, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 14, 14, 64)        36928     \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 7, 7, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 3136)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               1606144   \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 513       \n","                                                                 \n","=================================================================\n","Total params: 1,704,097\n","Trainable params: 1,704,097\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.optimizers import RMSprop\n","\n","model.compile(loss = 'binary_crossentropy',\n","              optimizer = RMSprop(learning_rate = 0.001),\n","              metrics = ['accuracy'])"],"metadata":{"id":"knJF592tqRvM","executionInfo":{"status":"ok","timestamp":1691585834975,"user_tz":-480,"elapsed":4,"user":{"displayName":"Kah Yong Chua","userId":"02499348339145863754"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# All images will be rescaled by 1./255\n","train_datagen = ImageDataGenerator(rescale=1/255)\n","validation_datagen = ImageDataGenerator(rescale = 1/255)\n","\n","# Flow training images in batches of 128 using train_datagen generator\n","train_generator = train_datagen.flow_from_directory(\n","        './horse-or-human/',  # This is the source directory for training images\n","        target_size=(300, 300),  # All images will be resized to 300x300\n","        batch_size=128,\n","        # Since we use binary_crossentropy loss, we need binary labels\n","        class_mode='binary')\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","      './validation-horse-or-human/',\n","      target_size = (300, 300),\n","      batch_size = 32,\n","      # Since we use binary_crossentropy loss, we need binary labels\n","      class_mode='binary'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tu4NKyCNq9c2","executionInfo":{"status":"ok","timestamp":1691585836041,"user_tz":-480,"elapsed":6,"user":{"displayName":"Kah Yong Chua","userId":"02499348339145863754"}},"outputId":"642138bf-f429-4d43-b9a5-20aa241e2e32"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1027 images belonging to 2 classes.\n","Found 256 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["history = model.fit(\n","      train_generator,\n","      steps_per_epoch=8,\n","      epochs=15,\n","      verbose=1,\n","      validation_data = validation_generator,\n","      validation_steps=8)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4RJVoOforbxy","executionInfo":{"status":"ok","timestamp":1691586018815,"user_tz":-480,"elapsed":175650,"user":{"displayName":"Kah Yong Chua","userId":"02499348339145863754"}},"outputId":"90649a8a-6e60-4066-c3ff-1d4337aa4efc"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","8/8 [==============================] - 24s 1s/step - loss: 0.7728 - accuracy: 0.5495 - val_loss: 0.6819 - val_accuracy: 0.5000\n","Epoch 2/15\n","8/8 [==============================] - 9s 1s/step - loss: 0.6810 - accuracy: 0.5573 - val_loss: 0.6365 - val_accuracy: 0.5273\n","Epoch 3/15\n","8/8 [==============================] - 9s 1s/step - loss: 0.6708 - accuracy: 0.4922 - val_loss: 0.5954 - val_accuracy: 0.8867\n","Epoch 4/15\n","8/8 [==============================] - 9s 1s/step - loss: 0.6557 - accuracy: 0.7130 - val_loss: 0.6542 - val_accuracy: 0.5234\n","Epoch 5/15\n","8/8 [==============================] - 9s 1s/step - loss: 1.1920 - accuracy: 0.6696 - val_loss: 1.6974 - val_accuracy: 0.5742\n","Epoch 6/15\n","8/8 [==============================] - 10s 1s/step - loss: 0.4597 - accuracy: 0.8254 - val_loss: 0.2585 - val_accuracy: 0.9023\n","Epoch 7/15\n","8/8 [==============================] - 10s 1s/step - loss: 0.5050 - accuracy: 0.8331 - val_loss: 2.1751 - val_accuracy: 0.5898\n","Epoch 8/15\n","8/8 [==============================] - 10s 1s/step - loss: 0.3525 - accuracy: 0.8496 - val_loss: 0.7764 - val_accuracy: 0.8750\n","Epoch 9/15\n","8/8 [==============================] - 8s 994ms/step - loss: 0.2491 - accuracy: 0.9010 - val_loss: 0.4495 - val_accuracy: 0.8633\n","Epoch 10/15\n","8/8 [==============================] - 9s 1s/step - loss: 0.1830 - accuracy: 0.9321 - val_loss: 1.0788 - val_accuracy: 0.8359\n","Epoch 11/15\n","8/8 [==============================] - 9s 1s/step - loss: 0.3879 - accuracy: 0.8543 - val_loss: 0.8531 - val_accuracy: 0.7656\n","Epoch 12/15\n","8/8 [==============================] - 9s 1s/step - loss: 0.2312 - accuracy: 0.9021 - val_loss: 4.3137 - val_accuracy: 0.6875\n","Epoch 13/15\n","8/8 [==============================] - 8s 989ms/step - loss: 0.2441 - accuracy: 0.9266 - val_loss: 1.3677 - val_accuracy: 0.8477\n","Epoch 14/15\n","8/8 [==============================] - 8s 980ms/step - loss: 0.1437 - accuracy: 0.9355 - val_loss: 1.0826 - val_accuracy: 0.8359\n","Epoch 15/15\n","8/8 [==============================] - 9s 1s/step - loss: 0.2003 - accuracy: 0.9333 - val_loss: 1.3055 - val_accuracy: 0.8008\n"]}]},{"cell_type":"code","source":["## NOTE: If you are using Safari and this cell throws an error,\n","## please skip this block and run the next one instead.\n","\n","import numpy as np\n","from google.colab import files\n","from tensorflow.keras.utils import load_img, img_to_array\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","\n","  # predicting images\n","  path = '/content/' + fn\n","  img = load_img(path, target_size=(300, 300))\n","  x = img_to_array(img)\n","  x /= 255\n","  x = np.expand_dims(x, axis=0)\n","\n","  images = np.vstack([x])\n","  classes = model.predict(images, batch_size=10)\n","  print(classes[0])\n","\n","  if classes[0]>0.5:\n","    print(fn + \" is a human\")\n","  else:\n","    print(fn + \" is a horse\")\n","\n"],"metadata":{"id":"GQ1Ks2Y6rmWz"},"execution_count":null,"outputs":[]}]}